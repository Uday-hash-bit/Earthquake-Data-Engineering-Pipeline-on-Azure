{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec103fb2-389a-42f0-9fa7-79d215263e76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get base parameters\n",
    "dbutils.widgets.text(\"bronze_params\", \"\")\n",
    "dbutils.widgets.text(\"silver_params\", \"\")\n",
    "\n",
    "bronze_params = dbutils.widgets.get(\"bronze_params\")\n",
    "silver_params = dbutils.widgets.get(\"silver_params\")\n",
    "\n",
    "# Debug: Print the raw input values for troubleshooting\n",
    "print(f\"Raw bronze_params: {bronze_params}\")\n",
    "print(f\"Raw silver_params: {silver_params}\")\n",
    "\n",
    "# Parse the JSON string\n",
    "bronze_data = json.loads(bronze_params)\n",
    "\n",
    "# Access individual variables\n",
    "start_date = bronze_data.get(\"start_date\", \"\")\n",
    "end_date = bronze_data.get(\"end_date\", \"\")\n",
    "silver_adls = bronze_data.get(\"silver_adls\", \"\")\n",
    "gold_adls = bronze_data.get(\"gold_adls\", \"\")\n",
    "silver_data = silver_params\n",
    "\n",
    "# Debug: Print the extracted values for verification\n",
    "print(f\"Start Date: {start_date}, End Date: {end_date}\")\n",
    "print(f\"Silver ADLS Path: {silver_adls}, Gold ADLS Path: {gold_adls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b8c47e9-06bc-405d-b0d4-02087d63ce49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reverse_geocoder\n  Downloading reverse_geocoder-1.5.1.tar.gz (2.2 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.5/2.2 MB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m12.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: numpy>=1.11.0 in /databricks/python3/lib/python3.12/site-packages (from reverse_geocoder) (2.1.3)\nRequirement already satisfied: scipy>=0.17.1 in /databricks/python3/lib/python3.12/site-packages (from reverse_geocoder) (1.15.1)\nBuilding wheels for collected packages: reverse_geocoder\n  Building wheel for reverse_geocoder (setup.py): started\n  Building wheel for reverse_geocoder (setup.py): finished with status 'done'\n  Created wheel for reverse_geocoder: filename=reverse_geocoder-1.5.1-py3-none-any.whl size=2268069 sha256=d0aa56659c3971859db10f3defef38cb749f65a7587ddde4b4c9160eb7f8c142\n  Stored in directory: /home/spark-fe9268fc-eeae-4255-bf56-1d/.cache/pip/wheels/11/e1/67/6e47f0ad41ea1843d37e1fbe79c6074744a1f4aace641cf800\nSuccessfully built reverse_geocoder\nInstalling collected packages: reverse_geocoder\nSuccessfully installed reverse_geocoder-1.5.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "# Ensure the below library is installed on your cluster\n",
    "!pip install reverse_geocoder\n",
    "import reverse_geocoder as rg\n",
    "\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a484d48-7cfd-444d-81e5-48c1b85ecd61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(silver_data).filter(col('time') > start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44a5df19-f6ee-4afe-a45c-243370dcc67e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.limit(100) # added to speed up processings as during testing it was proving a bottleneck\n",
    "# The problem is caused by the Python UDF (reverse_geocoder) being a bottleneck due to its non-parallel nature and high computational cost per task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7930876-bceb-43ba-a9f5-4465701d29b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_country_code(lat, lon):\n",
    "    \"\"\"\n",
    "    Retrieve the country code for a given latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    lat (float or str): Latitude of the location.\n",
    "    lon (float or str): Longitude of the location.\n",
    "\n",
    "    Returns:\n",
    "    str: Country code of the location, retrieved using the reverse geocoding API.\n",
    "\n",
    "    Example:\n",
    "    >>> get_country_details(48.8588443, 2.2943506)\n",
    "    'FR'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coordinates = (float(lat), float(lon))\n",
    "        result = rg.search(coordinates)[0].get('cc')\n",
    "        print(f\"Processed coordinates: {coordinates} -> {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing coordinates: {lat}, {lon} -> {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "173d15a2-0425-458d-b3c6-a635ef99efbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# registering the udfs so they can be used on spark dataframes\n",
    "get_country_code_udf = udf(get_country_code, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffbf9b5a-52e9-4f8b-8819-3d2cd4ea49d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\nProcessed coordinates: (48.8588443, 2.2943506) -> FR\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'FR'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_country_code(48.8588443, 2.2943506)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba03bf1f-943f-4ced-bff7-2f476d18bf6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# adding country_code and city attributes\n",
    "df_with_location = \\\n",
    "                df.\\\n",
    "                    withColumn(\"country_code\", get_country_code_udf(col(\"latitude\"), col(\"longitude\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e281f205-61b9-415c-8ee8-37520d1e4da0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- longitude: double (nullable = true)\n |-- latitude: double (nullable = true)\n |-- elevation: double (nullable = true)\n |-- title: string (nullable = true)\n |-- place_description: string (nullable = true)\n |-- sig: long (nullable = true)\n |-- mag: double (nullable = true)\n |-- magType: string (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- updated: timestamp (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1587bbf-b7f0-43dd-96f1-36619452652a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- longitude: double (nullable = true)\n |-- latitude: double (nullable = true)\n |-- elevation: double (nullable = true)\n |-- title: string (nullable = true)\n |-- place_description: string (nullable = true)\n |-- sig: long (nullable = true)\n |-- mag: double (nullable = true)\n |-- magType: string (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- updated: timestamp (nullable = true)\n |-- country_code: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_with_location.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9888242b-bd61-4190-b935-c325a6d04dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# adding significance classification\n",
    "df_with_location_sig_class = \\\n",
    "                            df_with_location.\\\n",
    "                                withColumn('sig_class', \n",
    "                                            when(col(\"sig\") < 100, \"Low\").\\\n",
    "                                            when((col(\"sig\") >= 100) & (col(\"sig\") < 500), \"Moderate\").\\\n",
    "                                            otherwise(\"High\")\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d78be280-10b3-4543-aaa8-1a4750192b02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- longitude: double (nullable = true)\n |-- latitude: double (nullable = true)\n |-- elevation: double (nullable = true)\n |-- title: string (nullable = true)\n |-- place_description: string (nullable = true)\n |-- sig: long (nullable = true)\n |-- mag: double (nullable = true)\n |-- magType: string (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- updated: timestamp (nullable = true)\n |-- country_code: string (nullable = true)\n |-- sig_class: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "df_with_location_sig_class.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb858298-fbf3-4e92-a2ae-f1f1e8628117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the transformed DataFrame to the Silver container\n",
    "gold_output_path = f\"{gold_adls}earthquake_events_gold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afffa6b3-9c7f-4a88-a563-1cff642f8611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Append DataFrame to Silver container in Parquet format\n",
    "df_with_location_sig_class.write.mode('append').parquet(gold_output_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}